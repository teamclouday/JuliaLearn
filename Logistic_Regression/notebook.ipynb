{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "[Reference 1](https://towardsdatascience.com/introduction-to-logistic-regression-66248243c148)  \n",
    "[Reference 2](https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24)  \n",
    "[ML Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html)  \n",
    "\n",
    "#### Sigmoid Function\n",
    "\n",
    "$$f(x)=\\frac{1}{1+e^{-(x)}}$$  \n",
    "\n",
    "which maps predicted values to probabilities  \n",
    "\n",
    "#### Hypothesis Representation\n",
    "\n",
    "$$Z=\\beta_0+\\beta_1X$$\n",
    "\n",
    "$$h\\Theta(x)=\\text{sigmoid}(Z)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1X)}}$$\n",
    "\n",
    "#### Cost Function\n",
    "\n",
    "$$\\text{Cost}(h_\\theta(x),y)=\n",
    "    \\begin{cases}\n",
    "    -\\log(h_\\theta(x)) & \\quad \\text{if } y = 1\\\\\n",
    "    -\\log(1-h_\\theta(x)) & \\quad \\text{if } y = 0\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "which is also\n",
    "\n",
    "$$J(\\theta)=-\\frac{1}{m}\\sum \\Big[ y^{(i)}\\log(h\\theta(x^{(i)})) + (1-y^{(i)})\\log(1-h\\theta(x^{(i)})) \\Big]$$\n",
    "\n",
    "which should be minimized\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)$$\n",
    "\n",
    "In this case:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_data: (100, 5)\n",
      "Shape 1of Y_data: (100,)\n"
     ]
    }
   ],
   "source": [
    "X_data = rand(Float32, (100, 5))\n",
    "Y_data = rand(0:1, 100)\n",
    "println(\"Shape of X_data: \", size(X_data))\n",
    "println(\"Shape 1of Y_data: \", size(Y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(Z::Number)::Float32\n",
    "    k = 1 + MathConstants.e ^ (-Float32(Z))\n",
    "    return 1 / k\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0f0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sigmoid function\n",
    "sigmoid(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5f0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5307113f0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0.123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32,2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scale (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "function scale(X::Array)::Array\n",
    "    @assert ndims(X) == 2\n",
    "    u = mean(X, dims=1) # compute mean\n",
    "    s = std(X, dims=1)  # compute standard deviation\n",
    "    res = (X .- u) ./ s\n",
    "    return res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: Float32[3.576279f-8 7.152557f-9 3.4570693f-8 1.2129546f-7 -6.198883f-8]\n",
      "Std: Float32[1.0 1.0 1.0 0.9999999 1.0]\n"
     ]
    }
   ],
   "source": [
    "X_data_scaled = scale(X_data)\n",
    "println(\"Mean: \", mean(X_data_scaled, dims=1))\n",
    "println(\"Std: \", std(X_data_scaled, dims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 2 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update sigmoid function\n",
    "function sigmoid(Z::Array)::Array\n",
    "    denom = 1 .+ (MathConstants.e .^ (-Z))\n",
    "    return 1 ./ denom\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×5 Array{Float32,2}:\n",
       " 0.262469  0.430346  0.449475  0.512657  0.432395\n",
       " 0.218255  0.781578  0.283412  0.228895  0.354363\n",
       " 0.620761  0.264099  0.596806  0.429298  0.189896\n",
       " 0.782045  0.514932  0.652579  0.216128  0.611644\n",
       " 0.137294  0.206546  0.573674  0.480437  0.364577\n",
       " 0.189417  0.73545   0.733499  0.384777  0.396689\n",
       " 0.808771  0.186872  0.346732  0.278399  0.361494\n",
       " 0.827221  0.258122  0.495954  0.850765  0.258863\n",
       " 0.193749  0.428589  0.846818  0.720241  0.734614\n",
       " 0.563925  0.209013  0.844589  0.509234  0.336402\n",
       " 0.280219  0.272508  0.730328  0.704026  0.794778\n",
       " 0.759372  0.247167  0.467897  0.783003  0.836474\n",
       " 0.634904  0.589769  0.504559  0.521567  0.526058\n",
       " ⋮                                       \n",
       " 0.209341  0.351337  0.543357  0.633214  0.826779\n",
       " 0.686036  0.487483  0.239373  0.674853  0.453041\n",
       " 0.808186  0.76354   0.733492  0.569827  0.520172\n",
       " 0.197301  0.388686  0.710178  0.375428  0.328935\n",
       " 0.801899  0.217809  0.519876  0.577182  0.483369\n",
       " 0.521042  0.767945  0.169486  0.776703  0.156573\n",
       " 0.807638  0.404384  0.847536  0.799507  0.697592\n",
       " 0.590161  0.751529  0.178615  0.744186  0.580631\n",
       " 0.743496  0.570693  0.827545  0.399954  0.705788\n",
       " 0.295029  0.51532   0.227855  0.344843  0.574288\n",
       " 0.239129  0.300184  0.335572  0.181645  0.424085\n",
       " 0.791337  0.813554  0.67934   0.561783  0.75318"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it\n",
    "sigmoid(X_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "# initialize beta (contains beta_0 and beta_1)\n",
    "beta = randn(size(X_data)[2]+1)\n",
    "println(size(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cost(X::Array, y::Array, beta::Array)::AbstractFloat\n",
    "    @assert ndims(X) == 2\n",
    "    @assert ndims(y) == 1\n",
    "    @assert ndims(beta) == 1\n",
    "    @assert size(X) == (size(y)[1], size(beta)[1]-1)\n",
    "    m = size(X)[1]\n",
    "    X_extended = hcat(X, ones(size(X)[1]))\n",
    "    X_combined = X_extended * reshape(beta, (size(beta)[1], 1))\n",
    "    prob = sigmoid(X_combined)\n",
    "    y_prep = reshape(y, (size(y)[1], 1))\n",
    "    vec = y_prep .* (log.(prob)) .+ (1 .- y_prep) .* (log.(1 .- prob))\n",
    "    cost = -1 / float(m) * sum(vec)\n",
    "    return cost\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2060107989382696"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it\n",
    "cost(X_data_scaled, Y_data, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_proba (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction function\n",
    "function predict_proba(X::Array, beta::Array)::Array\n",
    "    @assert ndims(X) == 2\n",
    "    @assert ndims(beta) == 1\n",
    "    @assert size(X)[2] == size(beta)[1]-1\n",
    "    X_extended = hcat(X, ones(size(X)[1]))\n",
    "    X_combined = X_extended * reshape(beta, (size(beta)[1], 1))\n",
    "    prob = sigmoid(X_combined)\n",
    "    prob = [(prob...)...] # flatten to 1d array\n",
    "    return prob\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Array{Float64,1}:\n",
       " 0.7158651629426267\n",
       " 0.6778311512661751\n",
       " 0.48559152038790354\n",
       " 0.9565381582600937\n",
       " 0.844693045745\n",
       " 0.8347089586825082\n",
       " 0.7550244417751586\n",
       " 0.09660030689390488\n",
       " 0.9568948936778026\n",
       " 0.846371377274259\n",
       " 0.9660385052646239\n",
       " 0.8821993763583131\n",
       " 0.692905908620481\n",
       " ⋮\n",
       " 0.9674160237556951\n",
       " 0.2835392736987466\n",
       " 0.6489047323612341\n",
       " 0.8598429865192947\n",
       " 0.7018694831578305\n",
       " 0.015301314652217627\n",
       " 0.833960704947854\n",
       " 0.22954285418176149\n",
       " 0.964364617292489\n",
       " 0.8308707823703232\n",
       " 0.925056402614478\n",
       " 0.8580497619197903"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba(X_data_scaled, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(X::Array, beta::Array)::Array\n",
    "    @assert ndims(X) == 2\n",
    "    @assert ndims(beta) == 1\n",
    "    @assert size(X)[2] == size(beta)[1]-1\n",
    "    X_extended = hcat(X, ones(size(X)[1]))\n",
    "    X_combined = X_extended * reshape(beta, (size(beta)[1], 1))\n",
    "    prob = sigmoid(X_combined)\n",
    "    prob = [(prob...)...] # flatten to 1d array\n",
    "    prob = map(m -> m >= 0.5 ? 1 : 0, prob)\n",
    "    return prob\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Array{Int64,1}:\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_data_scaled, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn! (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace learning function (Gradient Descent)\n",
    "function learn!(X::Array, y::Array, beta::Array, alpha::AbstractFloat)\n",
    "    @assert ndims(X) == 2\n",
    "    @assert ndims(y) == 1\n",
    "    @assert ndims(beta) == 1\n",
    "    @assert size(X) == (size(y)[1], size(beta)[1]-1)\n",
    "    predictions = predict_proba(X, beta)\n",
    "    offset = predictions .- y\n",
    "    offset = reshape(offset, (size(offset)[1], 1))\n",
    "    X_extended = hcat(X, ones(size(X)[1]))\n",
    "    gradients = X_extended' * offset\n",
    "    gradients = gradients ./ size(X)[1]\n",
    "    gradients = gradients .* alpha\n",
    "    beta .= beta .- [(gradients...)...]\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2847056981407118, -0.4377948464434017, 0.6514609110387156, -1.0704197309901735, 1.3742379679395351, 1.0673453103388324]\n"
     ]
    }
   ],
   "source": [
    "# try it\n",
    "println(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2834869286157294, -0.43693803301083645, 0.6507196071029732, -1.0682575866647863, 1.3720747411239878, 1.0659762979742713]\n"
     ]
    }
   ],
   "source": [
    "learn!(X_data_scaled, Y_data, beta, 0.01)\n",
    "println(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the logistic regression function\n",
    "function train(X::Array, y::Array; learning_rate::AbstractFloat=0.01, max_iter::Integer=10, return_all::Bool=false)::Array\n",
    "    @assert ndims(X) == 2\n",
    "    @assert ndims(y) == 1\n",
    "    @assert size(X)[1] == size(y)[1]\n",
    "    @assert max_iter >= 0\n",
    "    beta = Random.randn(size(X)[2]+1)\n",
    "    res = nothing\n",
    "    if return_all\n",
    "        res = reshape(beta, (1, size(beta)[1]))\n",
    "    else\n",
    "        res = beta\n",
    "    end\n",
    "    for i = 1:max_iter\n",
    "        if return_all\n",
    "            beta = learn(X, y, beta, learning_rate)\n",
    "            res = cat(res, reshape(beta, (1, size(beta)[1])), dims=1)\n",
    "        else\n",
    "            learn!(X, y, beta, learning_rate)\n",
    "            res .= beta\n",
    "        end\n",
    "    end\n",
    "    return res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy function\n",
    "function accuracy(y_pred::Array, y_real::Array)::AbstractFloat\n",
    "    @assert ndims(y_pred) == ndims(y_real) == 1\n",
    "    @assert size(y_pred) == size(y_real)\n",
    "    sum = 0\n",
    "    for (m, n) in zip(y_pred, y_real)\n",
    "        if m == n\n",
    "            sum += 1\n",
    "        end\n",
    "    end\n",
    "    return sum / size(y_pred)[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predict(X_data_scaled, beta), Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = train(X_data_scaled, Y_data, max_iter=100, learning_rate=0.5)\n",
    "accuracy(predict(X_data_scaled, weights), Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is linear model, we should not expect it to have a high accuracy on a completely randomly generated dataset  \n",
    "But we can see the improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
