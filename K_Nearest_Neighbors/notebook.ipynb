{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference 1](https://scikit-learn.org/stable/modules/neighbors.html)  \n",
    "[Reference 2](https://en.wikipedia.org/wiki/Nearest_neighbor_search)  \n",
    "[Reference 3](https://booking.ai/k-nearest-neighbours-from-slow-to-fast-thanks-to-maths-bec682357ccd)\n",
    "\n",
    "### Naive Approach  \n",
    "No transforming on original dataset (No training)  \n",
    "For prediction, iter through the original dataset, and find the nearest K data, by a given metrics  \n",
    "\n",
    "Can use euclidean distance:\n",
    "$$\\text{dist}(X_1, X_2) = \\|X_1 - X_2\\|$$\n",
    "\n",
    "A better approach is cosine similarity:\n",
    "$$\\text{sim}(X_1, X_2) = \\frac{X_1 \\cdot X_2}{\\|X_1\\| \\|X_2\\|}$$\n",
    "which computes the cos value between two vectors  \n",
    "1 for 0 degree, and less than 1 for $(0, \\pi]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../tools.jl\")\n",
    "import .JuTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Statistics\n",
    "import Random\n",
    "import LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cosine_sim (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cosine_sim(X1::Array{T} where T<:Number, X2::Array{T} where T<:Number)::AbstractFloat\n",
    "    @assert size(X1) == size(X2)\n",
    "    @assert ndims(X1) == ndims(X2) == 1\n",
    "    product = LinearAlgebra.dot(X1, X2)\n",
    "    X1_norm = LinearAlgebra.norm(X1, 2)\n",
    "    X2_norm = LinearAlgebra.norm(X2, 2)\n",
    "    return product / (X1_norm * X2_norm)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "X_data, Y_data = JuTools.data_generate_linear_2d()\n",
    "println(size(X_data))\n",
    "println(size(Y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 74.9  35.6\n",
       " 78.7  58.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[1:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803061697627"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(X_data[1, :], X_data[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8586498516465619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(X_data[1, :], X_data[3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "majority_vote (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define majority vote function\n",
    "function majority_vote(y::Array{T} where T<:Number)::Number\n",
    "    @assert ndims(y) == 1\n",
    "    unique_votes = Dict{Number, Integer}()\n",
    "    for y_val in y\n",
    "        if !haskey(unique_votes, y_val)\n",
    "            push!(unique_votes, y_val => 1)\n",
    "        else\n",
    "            unique_votes[y_val] += 1\n",
    "        end\n",
    "    end\n",
    "    result = sort(collect(unique_votes), by=m->m[2])\n",
    "    return result[end][1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_vote([1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output ordering is affected by input ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_vote([1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_vote([1,1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2)\n",
      "(300, 2)\n",
      "(700,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = JuTools.split_data(X_data, Y_data, shuffle=true, ratio=0.3)\n",
    "println(size(X_train))\n",
    "println(size(X_test))\n",
    "println(size(Y_train))\n",
    "println(size(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_naive (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define predict function, naive approach\n",
    "function predict_naive(X_predict::Array{T} where T<:Number, K::Integer, X_data::Array{T} where T<:Number, Y_data::Array{T} where T<:Number)::Array\n",
    "    @assert ndims(X_data) == 2\n",
    "    @assert ndims(Y_data) == 1\n",
    "    @assert size(X_data)[1] == size(Y_data)[1]\n",
    "    @assert 0 < ndims(X_predict) <= 2\n",
    "    @assert 0 < K < size(X_data)[1]\n",
    "    if ndims(X_predict) < 2\n",
    "        X_predict = reshape(X_predict, (1, size(X_predict)[1]))\n",
    "    end\n",
    "    @assert size(X_predict)[2] == size(X_data)[2]\n",
    "    result = Array{Number}(undef, size(X_predict)[1])\n",
    "    sim = Array{Tuple{Integer, AbstractFloat}}(undef, size(X_data)[1])\n",
    "    for i in 1:size(X_predict)[1]\n",
    "        vec_predict = X_predict[i, :]\n",
    "        for j in 1:size(X_data)[1]\n",
    "            vec_data = X_data[j, :]\n",
    "            vec_similarity = cosine_sim(vec_predict, vec_data)\n",
    "            sim[j] = (j, vec_similarity)\n",
    "        end\n",
    "        sort!(sim, by=m->m[2], rev=true)\n",
    "        K_nearest_votes = Y_data[[m[1] for m in sim[1:K]]]\n",
    "        result[i] = majority_vote(K_nearest_votes)\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300-element Array{Number,1}:\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = predict_naive(X_test, 5, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JuTools.compute_accuracy(Y_predict, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist_sim (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about dist similarity?\n",
    "function dist_sim(X1::Array{T} where T<:Number, X2::Array{T} where T<:Number)::AbstractFloat\n",
    "    @assert size(X1) == size(X2)\n",
    "    @assert ndims(X1) == ndims(X2) == 1\n",
    "    return sqrt(sum((X1 .- X2).^2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.60783768158363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_sim(X_data[1, :], X_data[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.87242529398077"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_sim(X_data[2, :], X_data[3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's greatly affected by the scale of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_naive_fun (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict_naive_fun(X_predict::Array{T} where T<:Number, K::Integer, X_data::Array{T} where T<:Number, Y_data::Array{T} where T<:Number)::Array\n",
    "    @assert ndims(X_data) == 2\n",
    "    @assert ndims(Y_data) == 1\n",
    "    @assert size(X_data)[1] == size(Y_data)[1]\n",
    "    @assert 0 < ndims(X_predict) <= 2\n",
    "    @assert 0 < K < size(X_data)[1]\n",
    "    if ndims(X_predict) < 2\n",
    "        X_predict = reshape(X_predict, (1, size(X_predict)[1]))\n",
    "    end\n",
    "    @assert size(X_predict)[2] == size(X_data)[2]\n",
    "    result = Array{Number}(undef, size(X_predict)[1])\n",
    "    sim = Array{Tuple{Integer, AbstractFloat}}(undef, size(X_data)[1])\n",
    "    for i in 1:size(X_predict)[1]\n",
    "        vec_predict = X_predict[i, :]\n",
    "        for j in 1:size(X_data)[1]\n",
    "            vec_data = X_data[j, :]\n",
    "            vec_similarity = dist_sim(vec_predict, vec_data)\n",
    "            sim[j] = (j, vec_similarity)\n",
    "        end\n",
    "        sort!(sim, by=m->m[2])\n",
    "        K_nearest_votes = Y_data[[m[1] for m in sim[1:K]]]\n",
    "        result[i] = majority_vote(K_nearest_votes)\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JuTools.compute_accuracy(predict_naive_fun(X_test, 5, X_train, Y_train), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It produces better score because X_data has 2 dimensions, which is best fit for computing euclidean distance  \n",
    "Eventually we'll be using cosine similarity in implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it (`predict_naive`) may be slow on large dataset, it is easy to implement and it works as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Dimensional Tree (K-d tree) Approach\n",
    "A space partitioning technique  \n",
    "Treat each data row as a point in `k`-dimensional space    \n",
    "[Wikipedia](https://en.wikipedia.org/wiki/K-d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct KdTree\n",
    "    X_data::Array{T} where T<:Number # 1d vector\n",
    "    Y_data::Number                   # number\n",
    "    child_l::Union{KdTree,Nothing}\n",
    "    child_r::Union{KdTree,Nothing}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_kdtree (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-d tree generator function\n",
    "function create_kdtree(X_data::Array{T} where T<:Number, Y_data::Array{T} where T<:Number)::KdTree\n",
    "    @assert ndims(X_data) == 2\n",
    "    @assert ndims(Y_data) == 1\n",
    "    @assert size(X_data)[1] == size(Y_data)[1]\n",
    "    function kdtree_recursive_generate(X_data::Array, Y_data::Array, depth::Integer, n_axes::Integer)::KdTree\n",
    "        curr_axis = mod(depth, n_axes) + 1 # array starts from 1\n",
    "        data_combined = hcat(X_data, Y_data)\n",
    "        data_combined = sortslices(data_combined, by=m->m[curr_axis], dims=1)\n",
    "        X_data = data_combined[:, 1:end-1]\n",
    "        Y_data = data_combined[:, end]\n",
    "        i_mid = div(size(X_data)[1], 2) + 1\n",
    "        node_X_data = X_data[i_mid, :]\n",
    "        node_Y_data = Y_data[i_mid]\n",
    "        node = KdTree(node_X_data, node_Y_data, nothing, nothing)\n",
    "        if i_mid > 1\n",
    "            node.child_l = kdtree_recursive_generate(X_data[1:i_mid-1,:], Y_data[1:i_mid-1], depth+1, n_axes)\n",
    "        end\n",
    "        if i_mid < size(X_data)[1]\n",
    "            node.child_r = kdtree_recursive_generate(X_data[i_mid+1:end,:], Y_data[i_mid+1:end], depth+1, n_axes)\n",
    "        end\n",
    "        return node\n",
    "    end\n",
    "    return kdtree_recursive_generate(X_data, Y_data, 0, size(X_data)[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.3, 63.2]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "kdtree = create_kdtree(X_data, Y_data)\n",
    "println(kdtree.X_data)\n",
    "println(kdtree.Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KdTree([35], 1, KdTree([10], 1, KdTree([5], 1, nothing, nothing), KdTree([30], 1, nothing, nothing)), KdTree([70], 1, KdTree([50], 1, nothing, nothing), nothing))\n"
     ]
    }
   ],
   "source": [
    "kdtree_test = create_kdtree(reshape([30,5,10,70,50,35], (6, 1)), [1,1,1,1,1,1])\n",
    "println(kdtree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_kdtree (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspired from https://stackoverflow.com/questions/1627305/nearest-neighbor-k-d-tree-wikipedia-proof/37107030#37107030\n",
    "# note that for kdtree search, we use euclidean distance\n",
    "function predict_kdtree(X_predict::Array{T} where T<:Number, kdtree::KdTree; K::Integer=5)::Array\n",
    "    @assert K > 0\n",
    "    @assert 0 < ndims(X_predict) <= 2\n",
    "    if ndims(X_predict) == 1\n",
    "        X_predict = reshape(X_predict, (1, size(X_predict)[1]))\n",
    "    end\n",
    "    @assert size(X_predict)[2] == size(kdtree.X_data)[1]\n",
    "\n",
    "    function kdtree_closest_max(kdtree_closest::Array{Union{KdTree, Nothing}},\n",
    "                kdtree_closest_val::Array{AbstractFloat})::Tuple{Integer, AbstractFloat}\n",
    "        default = (0, 0.0)\n",
    "        for i in 1:size(kdtree_closest)[1]\n",
    "            if kdtree_closest[i] === nothing\n",
    "                break\n",
    "            elseif default[1] == 0 || (kdtree_closest_val[i] > default[2])\n",
    "                default = (i, kdtree_closest_val[i])\n",
    "            end\n",
    "        end\n",
    "        return default\n",
    "    end\n",
    "    \n",
    "    function kdtree_update_nearest!(X_vec::Array, kdtree::KdTree, kdtree_closest::Array{Union{KdTree, Nothing}},\n",
    "                kdtree_closest_val::Array{AbstractFloat})\n",
    "        @assert size(kdtree_closest) == size(kdtree_closest_val)\n",
    "        distance = dist_sim(kdtree.X_data, X_vec)\n",
    "        if nothing in kdtree_closest\n",
    "            for i in 1:size(kdtree_closest)[1]\n",
    "                if kdtree_closest[i] === nothing\n",
    "                    kdtree_closest[i] = KdTree(kdtree.X_data, kdtree.Y_data, nothing, nothing)\n",
    "                    kdtree_closest_val[i] = distance\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "        else\n",
    "            curr_max = kdtree_closest_max(kdtree_closest, kdtree_closest_val)\n",
    "            if distance < curr_max[2]\n",
    "                kdtree_closest[curr_max[1]] = KdTree(kdtree.X_data, kdtree.Y_data, nothing, nothing)\n",
    "                kdtree_closest_val[curr_max[1]] = distance\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    function kdtree_recursive_search!(X_vec::Array, kdtree::KdTree, depth::Integer, n_axes::Integer, \n",
    "                kdtree_closest::Array{Union{KdTree, Nothing}}, kdtree_closest_val::Array{AbstractFloat})\n",
    "        @assert size(kdtree_closest) == size(kdtree_closest_val)\n",
    "        # check current node\n",
    "        kdtree_update_nearest!(X_vec, kdtree, kdtree_closest, kdtree_closest_val)\n",
    "        # run on children\n",
    "        curr_axis = mod(depth, n_axes) + 1 # array starts from 1\n",
    "        if X_vec[curr_axis] < kdtree.X_data[curr_axis]\n",
    "            if kdtree.child_l !== nothing\n",
    "                kdtree_recursive_search!(X_vec, kdtree.child_l, depth+1, n_axes, kdtree_closest, kdtree_closest_val)\n",
    "            end\n",
    "            if (X_vec[curr_axis] + kdtree_closest_max(kdtree_closest, kdtree_closest_val)[2] >= kdtree.X_data[curr_axis]) && kdtree.child_r !== nothing\n",
    "                kdtree_recursive_search!(X_vec, kdtree.child_r, depth+1, n_axes, kdtree_closest, kdtree_closest_val)\n",
    "            end\n",
    "        else\n",
    "            if kdtree.child_r !== nothing\n",
    "                kdtree_recursive_search!(X_vec, kdtree.child_r, depth+1, n_axes, kdtree_closest, kdtree_closest_val)\n",
    "            end\n",
    "            if (X_vec[curr_axis] - kdtree_closest_max(kdtree_closest, kdtree_closest_val)[2] <= kdtree.X_data[curr_axis]) && kdtree.child_l !== nothing\n",
    "                kdtree_recursive_search!(X_vec, kdtree.child_l, depth+1, n_axes, kdtree_closest, kdtree_closest_val)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    result = Array{Number}(undef, size(X_predict)[1])\n",
    "    for i in 1:size(X_predict)[1]\n",
    "        kdtree_closest = Array{Union{KdTree, Nothing}}(nothing, K)\n",
    "        kdtree_closest_val = Array{AbstractFloat}(undef, K)\n",
    "        kdtree_recursive_search!(X_predict[i, :], kdtree, 0, size(X_predict)[2], kdtree_closest, kdtree_closest_val)\n",
    "        K_nearest_votes = Number[]\n",
    "        for i in 1:K\n",
    "            if kdtree_closest[i] === nothing\n",
    "                break\n",
    "            else\n",
    "                push!(K_nearest_votes, kdtree_closest[i].Y_data)\n",
    "            end\n",
    "        end\n",
    "        result[i] = majority_vote(K_nearest_votes)\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133333333333333\n"
     ]
    }
   ],
   "source": [
    "kdtree_train = create_kdtree(X_train, Y_train)\n",
    "println(JuTools.compute_accuracy(predict_kdtree(X_test, kdtree_train, K=10), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ball Tree Approach\n",
    "A better space partition approach  \n",
    "More efficient than K-d Tree when searching  \n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Ball_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct BallTree\n",
    "    X_data::Array{T} where T<:Number\n",
    "    Y_data::Number\n",
    "    pivot::Union{Array{T},Nothing} where T<:Number # defines pivot point of hypersphere\n",
    "    radius::AbstractFloat                            # defines radius of hypersphere\n",
    "    child_l::Union{BallTree,Nothing}\n",
    "    child_r::Union{BallTree,Nothing}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_balltree (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspired from https://gist.github.com/jakevdp/5216193\n",
    "# ball tree generator function\n",
    "function create_balltree(X_data::Array{T} where T<:Number, Y_data::Array{T} where T<:Number)::BallTree\n",
    "    @assert ndims(X_data) == 2\n",
    "    @assert ndims(Y_data) == 1\n",
    "    @assert size(X_data)[1] == size(Y_data)[1]\n",
    "    balltree = nothing\n",
    "    if size(X_data)[1] == 1\n",
    "        balltree = BallTree(X_data[1, :], Y_data[1], nothing, 0.0, nothing, nothing)\n",
    "    else\n",
    "        # find pivot\n",
    "        pivot = vec(sum(X_data, dims=1)) ./ size(X_data)[1]\n",
    "        # find radius\n",
    "        radius = 0.0\n",
    "        for i in 1:size(X_data)[1]\n",
    "            X_vec = X_data[i, :]\n",
    "            dist = dist_sim(pivot, X_vec)\n",
    "            if dist > radius\n",
    "                radius = dist\n",
    "            end\n",
    "        end\n",
    "        # find greatest spread dimension\n",
    "        d_greatest_spread = 1\n",
    "        n_spread = 0.0\n",
    "        for i in 1:size(X_data)[2]\n",
    "            X_vec = X_data[:, i]\n",
    "            current_spread = abs(maximum(X_vec) - minimum(X_vec))\n",
    "            if current_spread > n_spread\n",
    "                d_greatest_spread = i\n",
    "                n_spread = current_spread\n",
    "            end\n",
    "        end\n",
    "        data_combined = hcat(X_data, Y_data)\n",
    "        data_combined = sortslices(data_combined, by=m->m[d_greatest_spread], dims=1)\n",
    "        X_data = data_combined[:, 1:end-1]\n",
    "        Y_data = data_combined[:, end]\n",
    "        i_mid = div(size(X_data)[1], 2) + 1\n",
    "        node_X_data = X_data[i_mid, :]\n",
    "        node_Y_data = Y_data[i_mid]\n",
    "        balltree = BallTree(node_X_data, node_Y_data, pivot, radius, nothing, nothing)\n",
    "        if i_mid > 1\n",
    "            balltree.child_l = create_balltree(X_data[1:i_mid-1,:], Y_data[1:i_mid-1])\n",
    "        end\n",
    "        if i_mid < size(X_data)[1]\n",
    "            balltree.child_r = create_balltree(X_data[i_mid+1:end,:], Y_data[i_mid+1:end])\n",
    "        end\n",
    "    end\n",
    "    return balltree\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.1, 50.5]\n",
      "1.0\n",
      "[50.810399999999994, 50.01620000000001]\n",
      "69.01783197551197\n"
     ]
    }
   ],
   "source": [
    "balltree = create_balltree(X_data, Y_data)\n",
    "println(balltree.X_data)\n",
    "println(balltree.Y_data)\n",
    "println(balltree.pivot)\n",
    "println(balltree.radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BallTree([35], 1, [33.333333333333336], 36.666666666666664, BallTree([10], 1, [15.0], 15.0, BallTree([5], 1, nothing, 0.0, nothing, nothing), BallTree([30], 1, nothing, 0.0, nothing, nothing)), BallTree([70], 1, [60.0], 10.0, BallTree([50], 1, nothing, 0.0, nothing, nothing), nothing))\n"
     ]
    }
   ],
   "source": [
    "balltree_test = create_balltree(reshape([30,5,10,70,50,35], (6, 1)), [1,1,1,1,1,1])\n",
    "println(balltree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_balltree (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search function for ball tree\n",
    "# similar to kdtree search\n",
    "function predict_balltree(X_predict::Array{T} where T<:Number, balltree::BallTree; K::Integer=5)::Array\n",
    "    @assert K > 0\n",
    "    @assert 0 < ndims(X_predict) <= 2\n",
    "    if ndims(X_predict) == 1\n",
    "        X_predict = reshape(X_predict, (1, size(X_predict)[1]))\n",
    "    end\n",
    "    @assert size(X_predict)[2] == size(balltree.X_data)[1]\n",
    "    \n",
    "    function balltree_closest_max(balltree_closest::Array{Union{BallTree, Nothing}},\n",
    "                balltree_closest_val::Array{AbstractFloat})::Tuple{Integer, AbstractFloat}\n",
    "        # find the maximum value in balltree_closest_val\n",
    "        # return its index and value\n",
    "        default = (0, 0.0)\n",
    "        for i in 1:size(balltree_closest)[1]\n",
    "            if balltree_closest[i] === nothing\n",
    "                break\n",
    "            elseif default[1] == 0 || (balltree_closest_val[i] > default[2])\n",
    "                default = (i, balltree_closest_val[i])\n",
    "            end\n",
    "        end\n",
    "        return default\n",
    "    end\n",
    "    \n",
    "    function balltree_update_nearest!(X_vec::Array, balltree::BallTree, balltree_closest::Array{Union{BallTree, Nothing}},\n",
    "                balltree_closest_val::Array{AbstractFloat})\n",
    "        # update current node by distance\n",
    "        @assert size(balltree_closest) == size(balltree_closest_val)\n",
    "        distance = dist_sim(balltree.X_data, X_vec)\n",
    "        if nothing in balltree_closest\n",
    "            for i in 1:size(balltree_closest)[1]\n",
    "                if balltree_closest[i] === nothing\n",
    "                    balltree_closest[i] = balltree\n",
    "                    balltree_closest_val[i] = distance\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "        else\n",
    "            curr_max = balltree_closest_max(balltree_closest, balltree_closest_val)\n",
    "            if distance < curr_max[2]\n",
    "                balltree_closest[curr_max[1]] = balltree\n",
    "                balltree_closest_val[curr_max[1]] = distance\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    function balltree_recursive_search!(X_vec::Array, balltree::BallTree, balltree_closest::Array{Union{BallTree, Nothing}},\n",
    "            balltree_closest_val::Array{AbstractFloat})\n",
    "        # recursively search a balltree for K nearest neighbors\n",
    "        @assert size(balltree_closest) == size(balltree_closest_val)\n",
    "        if (!(nothing in balltree_closest) && (balltree.pivot !== nothing)\n",
    "                && (dist_sim(X_vec, balltree.pivot) - balltree.radius >= \n",
    "                    balltree_closest_max(balltree_closest, balltree_closest_val)[2]))\n",
    "            return nothing\n",
    "        end\n",
    "        # check current node\n",
    "        balltree_update_nearest!(X_vec, balltree, balltree_closest, balltree_closest_val)\n",
    "        # run on children\n",
    "        if balltree.child_l === nothing || balltree.child_r === nothing\n",
    "            if balltree.child_l !== nothing\n",
    "                balltree_recursive_search!(X_vec, balltree.child_l, balltree_closest, balltree_closest_val)\n",
    "            end\n",
    "            if balltree.child_r !== nothing\n",
    "                balltree_recursive_search!(X_vec, balltree.child_r, balltree_closest, balltree_closest_val)\n",
    "            end\n",
    "        else\n",
    "            dist_left = dist_sim(X_vec, balltree.child_l.X_data)\n",
    "            dist_right = dist_sim(X_vec, balltree.child_r.X_data)\n",
    "            if dist_left < dist_right\n",
    "                balltree_recursive_search!(X_vec, balltree.child_l, balltree_closest, balltree_closest_val)\n",
    "                balltree_recursive_search!(X_vec, balltree.child_r, balltree_closest, balltree_closest_val)\n",
    "            else\n",
    "                balltree_recursive_search!(X_vec, balltree.child_r, balltree_closest, balltree_closest_val)\n",
    "                balltree_recursive_search!(X_vec, balltree.child_l, balltree_closest, balltree_closest_val)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    result = Array{Number}(undef, size(X_predict)[1])\n",
    "    for i in 1:size(X_predict)[1]\n",
    "        balltree_closest = Array{Union{BallTree, Nothing}}(nothing, K)\n",
    "        balltree_closest_val = Array{AbstractFloat}(undef, K)\n",
    "        balltree_recursive_search!(X_predict[i, :], balltree, balltree_closest, balltree_closest_val)\n",
    "        K_nearest_votes = Number[]\n",
    "        for i in 1:K\n",
    "            if balltree_closest[i] === nothing\n",
    "                break\n",
    "            else\n",
    "                push!(K_nearest_votes, balltree_closest[i].Y_data)\n",
    "            end\n",
    "        end\n",
    "        result[i] = majority_vote(K_nearest_votes)\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "balltree_train = create_balltree(X_train, Y_train)\n",
    "println(JuTools.compute_accuracy(predict_balltree(X_test, balltree_train, K=20), Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
